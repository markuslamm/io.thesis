\chapter{Requirements Analysis and Specification}

After a short introduction to the basic terms and Apache Flink and Apache Kafka in
context of stream processing, this chapter examines what different kind of data are available
for both of the systems. According to the results of the data analysis, the functional and
non-functional requirements of the software system which is forming the core of the present
thesis will be defined.

\section{Data Analysis}


\section{Data Quality}

After identification the main sources available
%
%Define DQ, evaluate quality for data above

\section{Functional Requirements}
see Main goal, ased on the data analysis,...TODO
%Collect DStat system data
%Collect JVM data for Apache Flink and Apache Kafka
%Collect
%
%
%
%
%The main objective of this bachelor thesis is to implement a software solution to collect ....
%"COLLECT EVERYTHING!
%live and historical sources
%
%Describe "big picture" functionality see \cite{VanL14}, follows distributed character of Big Data Analytics
%Applications, provide "on demand" data collection, as much data as possible, realtime?, three main components,
%break down for:
\subsection{Collection}
%collect data in clustered environments

\subsection{Transport}
%Scalability with message broker

\subsection{Persistence}
%Accessibility for AI, UI applications

\section{Non-Functional Requirements}
%Performance, scalability,
%simplicity, modifiability, visibility, portability, and reliability

\section{Summary}