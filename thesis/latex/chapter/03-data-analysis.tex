\chapter{Analysis}

After a short introduction to the basic terms and Apache Flink and Apache Kafka in
context of big data and stream processing, this chapter examines what different kind of
data are available for both of the systems to build the foundation of the functional and
non-functional requirements to be defined in Chapter 5 Requirements and Specification.

In preparation of this thesis my supervisor Prof. Dr. Stefan Edlich once said \textit{"Sie sammeln
alles, was nicht bei drei auf dem Baum ist"}. According to this statement, the main focus
of the coming section is the analysis of available data that will be collected by the software
solution and not a deeper exploration according to the relevance and quality of data that
is available for Apache Flink and Apache Kafka.

\textit{"You can only control what you observe and measure."}\cite{Ebert07}. Even though logfiles, both
provided by Apache Flink and Apache Kafka, are usefull for tracing problems in software
systems, problems can be tracked and potential sources of error can be identified much
earlier by collecting and storing system and application data at runtime to describe the
state of the entire system at a given point in time.

Due to the distributed character of Apache Flink and Apache Kafka, where a system is
composed of several interacting components, the examination of log data is not an
adequate choice to gain insight into a distributed system containing several components.\cite{VanL14}.

Runtime data to collect can be divided in three levels of abstraction:

\begin{enumerate}
    \item \textbf{Business data:} The highest level of abstraction, often refered to as Key Performance
    Indicators(KPI), these data expresses direct business related values and
    usually have very little reference to technical details. As an example, the number of
    sales in an online shop.
    \item \textbf{Application data:} On the middle level of abstraction, application data already
    contains many more technical details and refers to specific applications, like the
    number of GET requests and their corresponding HTTP Status response codes of a
    REST-based service.
    \item \textbf{System data:} The lowest level of abstraction, data provided by the underlying
    systems an application is running on such as cpu, memory, network, or system utilization.
\end{enumerate}

Based on Apache Flink and Apache Kafka, the following section discusses the data provided
by both of the systems and tries a classification based on the abtraction levels.

\section{System data}

System data refers to the data provided by the computer system on the lowest level of
abstraction and allows observation of system-related data. On unix-based systems, a
variety of system tools is well known to system administrators to monitor the performance
of servers, like vmstat (memory utilization), ifstat (network usage) or iostat (system
input/output) \cite{Hoeb12}.

Another existing tool is called "DStat Versatile Resource Statistics Tool" and is described
as follows: \textit{"Dstat is a versatile replacement for vmstat, iostat, netstat and ifstat. Dstat
overcomes some of their limitations and adds some extra features, more counters and flexibility.
Dstat is handy for monitoring systems during performance tuning tests, benchmarks
or troubleshooting. Dstat allows you to view all of your system resources in real-time, you
can eg. compare disk utilization in combination with interrupts from your IDE controller,
or compare the network bandwidth numbers directly with the disk throughput (in the same
interval)."}\cite{Wieers16}

Dstat is a command line tool, the following figure shows the immediate output of running
the application with the argument "--full", which expands more detailed information about
multiple cpus and network interfaces:

\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\textwidth]{../images/06-dstat-full.png}
	\caption{Output "dstat --full"}
	\label{dstat-output}
\end{figure}

Additionally, Dstat provides multiple parameters to specify the data to be displayed, e.g.
--cpu, --disk, --net, and many more. Used in combination, the data can be grouped in the
following categories according to the parameters:

\begin{table}[H]
    \begin{tabular}{ll}
        \textbf{Category} & \textbf{Dstat parameters} \\
        cpu & ("--cpu", "--top-cpu-adv", "--top-cputime", "--top-cputime-avg")\\
        disk & ("--disk", "--disk-tps", "--disk-util")\\
        net & ("--net", "--socket", "--tcp", "--udp")\\
        io & ("--io", "--top-io-adv", "--lock", "--fs")\\
        memory & ("--mem", "--top-mem", "--page", "--swap", "--vm")\\
        system & ("--sys", "--load", "--ipc", "--unix")\\
        process & ("--proc", "--proc-count", "--top-latency", "--top-latency-avg")\\
    \end{tabular}
    \caption{Dstat data categories}
    \label{tbl:dstatcategories}
\end{table}

Although the parameters are mostly self-explanatory, a list containing short descriptions
for each of the parameter used in Chapter 4 Architecture and Implementation is available in
Appendix. TODO Based on the data in the extracted categories, Dstat can be considered
as a source that gives a fairly complete picture of the state of a system.

Dstat is a tool only available for unix systems, and therefore not available for Windows or
Macintosh. Since Apache Flink and Apache Kafka are operated on Unix systems in most
cases, this fact can be neglected because this tool offers a wide range of data to describe
the system state a certain point of time.

\section{Application data}

Every application running on the Java Virtual Machine, can be accessed via JMX as discussed
in Chapter 2 Basic Concepts. According the specification, every implementation of the JVM contains
implementations for a basic set of management interfaces, that enables the access separate parts of JVM related data,
located in the package "java.lang.management" \cite{Javadoc16}.

\begin{table}[H]
    \begin{tabular}{ll}
        \textbf{Management interface} & \textbf{JMX ObjectName} \\
        ClassLoadingMXBean & java.lang:type=ClassLoading \\
        OperatingSystemMXBean & java.lang:type=OperatingSystem \\
        RuntimeMXBean & java.lang:type=Runtime \\
        ThreadMXBean & java.lang:type=Threading \\
        MemoryMXBean & java.lang:type=Memory \\
        BufferPoolMXBean & java.nio:type=BufferPool,name=* \\
        GarbageCollectorMXBean & java.lang:type=GarbageCollector,name=* \\
        MemoryManagerMXBean & java.lang:type=MemoryManager,name=* \\
        MemoryPoolMXBean & java.lang:type=MemoryPool,name=* \\
    \end{tabular}
    \caption{"Default" JMX JVM data}
    \label{tbl:jmxjvmdata}
\end{table}

There's a difference in the way of data access between the object name containing an asterisk "*"
and the one the ones that doesn't. The asterisk indicates the existence of multiple MBeans for a given query string,
the result of a query for the object name "java.lang:type=GarbageCollector,name=*" results in multiple data sets according
to existing garbage collector names.

This "default" set of management interfaces provides a deep insight into JVM data, is
available for Apache Flink and Apache Kafka and will be included in the software solution
in Chapter 4.

\subsection{Apache Flink}

Apache Flink provides application data via its monitoring API, a RESTful API, see
Chapter 2 Basic Concepts, that delivers JSON data based on HTTP
GET requests. It can be used to query general cluster information and status and
statistics of running and completed jobs. The dashboard that comes with Apache Flink
uses this monitoring API, but is designed to be used also by custom monitoring tools. The
monitoring API runs as part of the JobManager and listens at post 8081 by default. All requests
are of the sample form http://hostname:8081/jobs, below a list of available REST resources that
will be used to fetch cluster- and job-related data for Apache Flink in Chapter 6 Implementation,
see Appendix A for the corresponding JSON responses.

\begin{table}[H]
    \begin{tabular}{ll}
        \textbf{API path} & \textbf{Description} \\
        /config & Server setup \\
        /overview & Cluster status \\
        /jobs & Job ids by status running, finished, failed, canceled. \\
        /jobs/{jobId} & Job details, dataflow plan, status, timestamps of state transitions \\
        /jobs/{jobId}/exceptions &  Exceptions that have been observed by the job \\
        /jobs/{jobId}/config & User-defined execution config used by the job \\
    \end{tabular}
    \caption{Dstat data categories}
    \label{tbl:dstatcategories}
\end{table}

Appendix A provides a list with sample JSON response according to this REST endpoints. TODO

Since version 1.1.0, Apache Flink also provides a rudimentary metrics system that exposes
basic data for the Java Virtual Machine, the JobManagers and TaskManagers are running
on. This data includes inter alia cpu usage or memory consumption, as well as basic
information about running jobs. According to the "default" JVM data described in Table 3.2
and the data provided by the monitoring REST api, the metrics system in its current version
represents just an excerpt of the data that will be collected anyway.

\subsection{Apache Kafka}

In addition to the standard interfaces and MBeans that come with the implementation
of the JVM, Apache Kafka provides a set of managed resources providing application
specific metrics concerning the Kafka domain, reaching from global broker metrics, global
connection metrics to metrics per topic like in- and outgoing byte rates for example. Based
on the requirement to collect as much data as possible, the data of all provided resources
will be collected, the complete list of MBeans observed for Apache Kafka is available in
Appendix A.

\section{Data Quality}

The following covers the basics of the term "Data Quality" and examines the data sources
introduced above based on common quality criteria.

Data quality refers to the quality of data as it is provided by measurements and describes the
ability of data to represent the mapping from an empirical system("the real world" we operate in)
to the numeric system correctly with the main goal to satisfy a given need or objective. \cite{Ebert07}

\cite{Daqua13} and  \cite{Ebert07} introduce multiple common criteria for measuring the quality of data,
from which a selection is made to check the data previously described on their quality:

\begin{enumerate}
    \item \textbf{Correctness, Faultlessness:}
    The data correspond to the entities of the real world, that is, the data represent the reality.

    \item \textbf{Consistency:}
    Recorded data sets does not show discrepancies, logical contradictions or errors when compared
    among themselves.

    \item \textbf{Reliability, Traceability:}
    The origin of the data is traceable and the sources are trusted.

    \item \textbf{Completeness:}
    The required information is available and no data values are missing or in an unusable state.

    \item \textbf{Accuracy:}
    Expresses the mapping from the empirical system to the intended numerical system. Recorded values
    conform to actual values,

    \item \textbf{Timeliness:}
    All data records correspond to the current state of the modeled world and thus are not outdated.
    The data are the actual properties of an object from a timely manner.
\end{enumerate}


%
%TODO Define DQ, evaluate quality for data above

\section{Summary}

According to these examinations, the following matrix of data sources results for Apache
Flink and Apache Kafka:
\begin{table}[H]
\begin{tabular}{lll}
 & \textbf{Apache Flink} & \textbf{Apache Kafka} \\
\textbf{System data (Dstat)} & X & X \\
\textbf{JVM data (JMX)} & X & X \\
\textbf{Application data (JMX)} & X & X \\
\textbf{Application data (REST)} & X & - \\
\end{tabular}
\caption{Data source matrix}
\label{data-source-matrix}
\end{table}



%TODO: Correlation sytem and application data

In this Chapter, we discussed Dstat as a system tool that is due to its amount of available parameters
an adequate source for retriving system data for both Apache Flink and Kafka.
