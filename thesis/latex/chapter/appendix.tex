\appendix

\chapter{}
\addcontentsline{toc}{chapter}{Appendix A}

\section{Apache Kafka 0.9.0.1 MBeans}
\begin{table}[H]
    \begin{tabular}{l}
        \textbf{JMX ObjectName} \\
        kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs \\
        kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec \\
        kafka.controller:type=KafkaController,name=ActiveControllerCount \\
        kafka.controller:type=KafkaController,name=OfflinePartitionsCount \\
        kafka.controller:type=KafkaController,name=PreferredReplicaImbalanceCount \\
        kafka.network:type=Processor,name=IdlePercent,networkProcessor=* \\
        kafka.server:type=socket-server-metrics,networkProcessor=* \\
        kafka.server:type=controller-channel-metrics,broker-id=* \\
        kafka.server:type=ReplicaManager,name=IsrExpandsPerSec \\
        kafka.server:type=ReplicaManager,name=IsrShrinksPerSec \\
        kafka.server:type=ReplicaManager,name=LeaderCount \\
        kafka.server:type=ReplicaManager,name=PartitionCount \\
        kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions \\
        kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent \\
        kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec,topic=* \\
        kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec,topic=* \\
        kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=* \\
        kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=* \\
        kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec,topic=* \\
        kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec,topic=* \\
        kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec,topic=* \\
        kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec \\
        kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=* \\
        kafka.coordinator:type=GroupMetadataManager,name=NumGroups \\
        kafka.coordinator:type=GroupMetadataManager,name=NumOffsets \\
    \end{tabular}
    \caption{Collected Kafka MBeans}
    \label{app:kafka-mbeans}
\end{table}

\section{Docker Configuration}
\label{app:docker-config}
\begin{lstlisting}[caption={"Collector-Platform" cluster configuration}, captionpos=b, label={lst:docker-config-all}]
version: '2'
services:

  consul:
    image: "progrium/consul:latest"
    container_name: "consul"
    hostname: "consul"
    ports:
      - "8400:8400"
      - "8500:8500"
      - "8600:53"
    command: "-server -bootstrap-expect 1 -ui-dir /ui"

  zookeeper:
    container_name: zookeeper
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"

  kafka:
    container_name: kafka
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
      - "9997:9999"   # jmx
      - "9097:9091"   # collector-client
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_HOST_NAME: 192.168.2.100
      KAFKA_CREATE_TOPICS: "collector-outbound-topic:1:1,flink-outbound-topic:1:1"
      JMX_PORT: 9999
      SPRING_PROFILES_ACTIVE: kafka-broker-jmx
      SPRING_CLOUD_CONSUL_HOST: consul
      SPRING_CLOUD_CONSUL_PORT: 8500
      CLIENT_PORT: 9091
      KAFKA_BROKER_ADDRESS: kafka:9092
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper
      - consul

  flink-jobmanager:
    image: flink
    container_name: flink-jobmanager
    ports:
      - "8081:8081"   # webui
      - "9999:9999"   # jmx
      - "9099:9091"   # collector-client
    command: jobmanager
    volumes:
      - /usr/local/flink/conf
    depends_on:
      - consul
      - kafka
      - elk
    environment:
      SPRING_PROFILES_ACTIVE: dstat,jvm-jmx,flink-jmx,flink-rest
      SPRING_CLOUD_CONSUL_HOST: consul
      SPRING_CLOUD_CONSUL_PORT: 8500
      CLIENT_PORT: 9091
      KAFKA_BROKER_ADDRESS: kafka:9092

  flink-taskmanager:
    image: flink
    container_name: flink-taskmanager
    ports:
      - "9998:9999"   # jmx
      - "9098:9091"   # collector-client
    command: taskmanager
    volumes_from:
      - flink-jobmanager
    depends_on:
      - flink-jobmanager
      - consul
      - kafka
      - elk
    environment:
      SPRING_PROFILES_ACTIVE: flink-rest #,jvm-jmx
      SPRING_CLOUD_CONSUL_HOST: consul
      SPRING_CLOUD_CONSUL_PORT: 8500
      CLIENT_PORT: 9091
      KAFKA_BROKER_ADDRESS: kafka:9092
      FLINK_REST_HOST: flink-jobmanager
      FLINK_REST_PORT: 8081

  elk:
    container_name: elk
    image: sebp/elk
    ports:
      - "5601:5601"
      - "9200:9200"
      - "5044:5044"
      - "5000:5000"
    depends_on:
      - zookeeper
      - kafka

  collector-manager:
    container_name: collector-manager
    image: io.thesis/collector-manager
    ports:
      - "9090:9090"
    depends_on:
      - consul
    environment:
      SERVER_PORT: 9090
      SPRING_CLOUD_CONSUL_HOST: consul
      SPRING_CLOUD_CONSUL_PORT: 8500
\end{lstlisting}

\section{DVD Content}

The content of the enclosed persistent medium represents the final state of produced artefarcts according to the thesis and
can be located under \newline \verb|https://github.com/markuslamm/io.thesis|. The repository follows the following structure:

\begin{itemize}
	\item \textbf{collector-client}, source code
	\item \textbf{collector-data-processor}, source code
	\item \textbf{collector-manager}, source code
	\item \textbf{collectors}, source code
	\item \textbf{infrastructure}, required extrenal Docker images
	\item \textbf{thesis-commons}, , source code
	\item \textbf{thesis}, Latex related
	\item \textbf{.gitignore}, Git ignore definitions
	\item \textbf{.travis.yml}, Travis CI build descriptor
	\item \textbf{README.md}
	\item \textbf{build-docker-images.sh}, sh script for building all source and Docker artefarcts
	\item \textbf{docker-compose.yml} Cluster configuration
	\item \textbf{Thesis-Print.pdf} Final thesis version for printing
	\item \textbf{Thesis-Screen.pdf} Final thesis version for reading on screen, displays references
\end{itemize}

\section{Cluster Setup}
The application was developed and in the following software environment:

\begin{itemize}
	\item Ubuntu 16.04 LTS
	\item Oracle Java 8
	\item Maven 3.3.3
	\item Docker 1.11.2
	\item docker-compose 1.7.1
\end{itemize}

The following software needs to be installed to run the application:

\begin{itemize}
    \item Java 8, (http://www.oracle.com/technetwork/java/javase/downloads/index.html)
    \item Maven, (https://maven.apache.org/install.html)
    \item Docker , (https://docs.docker.com/engine/installation/)
    \item Docker-Compose, (https://docs.docker.com/compose/install/)
\end{itemize}

Build application sources and required Docker images:

\verb|./build-docker-images.sh|

This will  may take a while, depending on your internet connection.

Start application:

\verb|docker-compose up|

This will startup containers for Flink-JobManager/Taskmanager, Kafka, ELK, Consul and the collector-server and make take some time as well.

Go to collector-server UI: http://{DOCKER-HOST}:9090.

There should be three registered clients running on Flink-JobManager/Taskmanager and the Kafka broker.